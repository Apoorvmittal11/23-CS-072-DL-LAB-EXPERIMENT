{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cskJaZj2nNY"
      },
      "source": [
        "#**CNN IMPLEMENTATION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTPwOGxC2mWK"
      },
      "source": [
        "**Objective**\n",
        "\n",
        "The objective of this lab is to implement Convolutional Neural Networks (CNNs) to classify\n",
        "images in the Cats vs. Dogs dataset and the CIFAR-10 dataset. You will explore different\n",
        "configurations by experimenting with:\n",
        "\n",
        "● 3 Activation Functions\n",
        "\n",
        "\n",
        "● 3 Weight Initialization Techniques\n",
        "\n",
        "● 3 Optimizers\n",
        "\n",
        "Additionally, you will compare your best CNN model for both datasets with a pretrained\n",
        "ResNet-18 model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0b4OViG871f",
        "outputId": "fa03c3e9-bbe6-4da2-ac2f-c76214587de5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import copy\n",
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "from PIL import Image\n",
        "import shutil\n",
        "\n",
        "\n",
        "DATASET_NAME = 'CATS_DOGS'\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 2\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "def download_and_extract_catsdogs(root_dir='./data'):\n",
        "    # [FIX] Updated URL to the new '5340.zip' version (Old '3367a.zip' is dead)\n",
        "    url = \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\"\n",
        "    filename = \"cats_dogs.zip\"\n",
        "    download_path = os.path.join(root_dir, filename)\n",
        "    extract_path = os.path.join(root_dir, 'cats_dogs_extracted')\n",
        "\n",
        "    # Create data directory\n",
        "    if not os.path.exists(root_dir):\n",
        "        os.makedirs(root_dir)\n",
        "\n",
        "    # 1. Download\n",
        "    if not os.path.exists(download_path) and not os.path.exists(extract_path):\n",
        "        print(\"Downloading Cats vs Dogs dataset (New Version 5340)...\")\n",
        "        try:\n",
        "            # Add user-agent to avoid 403 forbidden errors on some networks\n",
        "            opener = urllib.request.build_opener()\n",
        "            opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
        "            urllib.request.install_opener(opener)\n",
        "            urllib.request.urlretrieve(url, download_path)\n",
        "            print(\"Download complete.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Download failed: {e}\")\n",
        "            raise RuntimeError(\"Could not download dataset. Check your internet connection.\")\n",
        "\n",
        "    # 2. Extract\n",
        "    if not os.path.exists(extract_path):\n",
        "        print(\"Extracting dataset...\")\n",
        "        try:\n",
        "            with zipfile.ZipFile(download_path, 'r') as zip_ref:\n",
        "                zip_ref.extractall(root_dir)\n",
        "\n",
        "            # The zip contains a 'PetImages' folder. We rename it to avoid conflicts.\n",
        "            original_folder = os.path.join(root_dir, 'PetImages')\n",
        "            if os.path.exists(original_folder):\n",
        "                os.rename(original_folder, extract_path)\n",
        "            print(\"Extraction complete.\")\n",
        "        except zipfile.BadZipFile:\n",
        "            print(\"Error: The downloaded zip file is corrupted. Please delete it and try again.\")\n",
        "            return None\n",
        "    else:\n",
        "        print(\"Dataset already found.\")\n",
        "\n",
        "    # 3. Clean Corrupt Images\n",
        "    print(\"Scanning for corrupt images (this is required to prevent crashes)...\")\n",
        "    folders = ['Cat', 'Dog']\n",
        "    removed = 0\n",
        "    for folder in folders:\n",
        "        folder_path = os.path.join(extract_path, folder)\n",
        "        if not os.path.exists(folder_path): continue\n",
        "\n",
        "        for file in os.listdir(folder_path):\n",
        "            file_path = os.path.join(folder_path, file)\n",
        "            try:\n",
        "                # Check 1: File size\n",
        "                if os.path.getsize(file_path) == 0:\n",
        "                    os.remove(file_path)\n",
        "                    removed += 1\n",
        "                    continue\n",
        "\n",
        "                # Check 2: Verify Image Header\n",
        "                with Image.open(file_path) as img:\n",
        "                    img.verify()\n",
        "\n",
        "            except (IOError, SyntaxError, Image.UnidentifiedImageError):\n",
        "                # print(f\"Removing corrupt file: {file}\")\n",
        "                try:\n",
        "                    os.remove(file_path)\n",
        "                    removed += 1\n",
        "                except: pass\n",
        "\n",
        "    print(f\"Cleanup complete. Removed {removed} corrupt images.\")\n",
        "    return extract_path\n",
        "\n",
        "def get_dataloaders(dataset_name):\n",
        "    print(f\"Preparing data for: {dataset_name}...\")\n",
        "\n",
        "    if dataset_name == 'CIFAR10':\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize((32, 32)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "        trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "        valset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "        num_classes = 10\n",
        "\n",
        "    elif dataset_name == 'CATS_DOGS':\n",
        "        # 1. Auto-download and get path\n",
        "        data_path = download_and_extract_catsdogs()\n",
        "\n",
        "        if data_path is None:\n",
        "            raise RuntimeError(\"Failed to prepare CATS_DOGS dataset.\")\n",
        "\n",
        "        # 2. Transforms (Resize is mandatory as images are different sizes)\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize((64, 64)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "\n",
        "        # 3. Create Dataset\n",
        "        # ImageFolder expects structure: root/class_x/xxx.jpg\n",
        "        full_dataset = torchvision.datasets.ImageFolder(root=data_path, transform=transform)\n",
        "\n",
        "        # 4. Split (80% Train, 20% Val)\n",
        "        train_size = int(0.8 * len(full_dataset))\n",
        "        val_size = len(full_dataset) - train_size\n",
        "        trainset, valset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
        "        num_classes = 2\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_loader = torch.utils.data.DataLoader(valset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    return train_loader, val_loader, num_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zu0DuE_g2mSy"
      },
      "source": [
        "# **Steps to Complete the Task**\n",
        "**1.CNN Implementation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3h_MGTr2mPZ"
      },
      "source": [
        "\n",
        "**● Define a CNN architecture:**\n",
        "\n",
        "o Experiment with different numbers of convolutional layers and filter sizes.\n",
        "\n",
        "o Include pooling layers and fully connected layers as needed.\n",
        "\n",
        "o Add dropout and batch normalization for better regularization and stability.\n",
        "**● Experiment with configurations:**\n",
        "\n",
        "o Implement 3 different activation functions:\n",
        "\n",
        "*  ReLU\n",
        "\n",
        "*  Tanh\n",
        "\n",
        "*  Leaky ReLU\n",
        "\n",
        "o Implement 3 different weight initialization techniques:\n",
        "\n",
        "*  Xavier Initialization\n",
        "\n",
        "*  Kaiming Initialization\n",
        "\n",
        "*  Random Initialization\n",
        "\n",
        "o Experiment with 3 optimizers:\n",
        "\n",
        "*  SGD\n",
        "\n",
        "*  Adam\n",
        "\n",
        "*  RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "v7EotQFj5VQ1"
      },
      "outputs": [],
      "source": [
        "class ModularCNN(nn.Module):\n",
        "    def __init__(self, activation_name, init_method, num_classes):\n",
        "        super(ModularCNN, self).__init__()\n",
        "\n",
        "        # [Step 1.1] Define CNN Architecture\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32) # [Step 1.1] Batch Normalization\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.pool = nn.MaxPool2d(2, 2) # [Step 1.1] Pooling Layers\n",
        "        self.dropout = nn.Dropout(0.5) # [Step 1.1] Dropout\n",
        "\n",
        "        # Calculate Flatten Size dynamically based on dataset\n",
        "        if num_classes == 10: # CIFAR-10 (32x32)\n",
        "            self.flatten_size = 64 * 8 * 8\n",
        "        else: # Cats vs Dogs (Resized to 64x64)\n",
        "            self.flatten_size = 64 * 16 * 16\n",
        "\n",
        "        self.fc1 = nn.Linear(self.flatten_size, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "        # [Step 1.2] Implement 3 different activation functions\n",
        "        if activation_name == 'relu':\n",
        "            self.activation = nn.ReLU()\n",
        "        elif activation_name == 'tanh':\n",
        "            self.activation = nn.Tanh()\n",
        "        elif activation_name == 'leaky_relu':\n",
        "            self.activation = nn.LeakyReLU()\n",
        "\n",
        "        # [Step 1.3] Implement 3 different weight initialization techniques\n",
        "        self.init_method = init_method\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.activation(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(self.activation(self.bn2(self.conv2(x))))\n",
        "        x = x.view(x.size(0), -1) # Flatten\n",
        "        x = self.dropout(self.activation(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "                if self.init_method == 'xavier':\n",
        "                    nn.init.xavier_uniform_(m.weight)\n",
        "                elif self.init_method == 'kaiming':\n",
        "                    nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
        "                elif self.init_method == 'random':\n",
        "                    nn.init.normal_(m.weight, mean=0, std=0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6ZgeNcb2mMj"
      },
      "source": [
        "**2.Training and Evaluation**\n",
        "\n",
        "● Train your CNN on each dataset using all combinations of activations, weight\n",
        "initializations, and optimizers.\n",
        "\n",
        "● Save the best-performing model for each dataset.\n",
        "\n",
        "● Save the weights of your best-performing models and upload them to a GitHub\n",
        "repository along with your code.\n",
        "\n",
        "● Use accuracy and loss metrics to evaluate performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hiIiFndF5V5M"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, train_loader, criterion, optimizer):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    return running_loss / total, correct / total\n",
        "\n",
        "def evaluate(model, val_loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return running_loss / total, correct / total\n",
        "\n",
        "def run_training_experiments(train_loader, val_loader, num_classes):\n",
        "    # Train using all combinations\n",
        "    activations = ['relu', 'tanh', 'leaky_relu']\n",
        "    inits = ['xavier', 'kaiming', 'random']\n",
        "    optimizers_list = ['sgd', 'adam', 'rmsprop']\n",
        "\n",
        "    best_acc = 0.0\n",
        "    best_config = \"\"\n",
        "    best_weights = None\n",
        "\n",
        "\n",
        "    for act in activations:\n",
        "        for init in inits:\n",
        "            for opt_name in optimizers_list:\n",
        "                print(f\"Training: Act={act}, Init={init}, Opt={opt_name}\")\n",
        "                model = ModularCNN(act, init, num_classes).to(device)\n",
        "\n",
        "\n",
        "                if opt_name == 'sgd':\n",
        "                    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "                elif opt_name == 'adam':\n",
        "                    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "                elif opt_name == 'rmsprop':\n",
        "                    optimizer = optim.RMSprop(model.parameters(), lr=0.001)\n",
        "\n",
        "                criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "                # Training Loop\n",
        "                for epoch in range(NUM_EPOCHS):\n",
        "                    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer)\n",
        "                    val_loss, val_acc = evaluate(model, val_loader, criterion)\n",
        "\n",
        "                # Save best performing model logic\n",
        "                if val_acc > best_acc:\n",
        "                    best_acc = val_acc\n",
        "                    best_config = f\"{act}_{init}_{opt_name}\"\n",
        "                    best_weights = copy.deepcopy(model.state_dict())\n",
        "                    print(f\"  -> New Best Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "    # [Step 2] Save weights of best-performing model\n",
        "    if best_weights:\n",
        "        torch.save(best_weights, f'best_model_{best_config}.pth')\n",
        "        print(f\"\\nBest Config Saved: {best_config} with Acc: {best_acc:.4f}\")\n",
        "\n",
        "    return best_acc, best_config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sd2eB_2I2mI7"
      },
      "source": [
        "**3.Transfer Learning with ResNet-18**\n",
        "\n",
        "● Fine-tune ResNet-18 on both datasets.\n",
        "\n",
        "● Compare its performance with your best CNN model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eJEjObrU2lNF"
      },
      "outputs": [],
      "source": [
        "def run_resnet_transfer(train_loader, val_loader, num_classes):\n",
        "    print(\"\\n--- Starting Transfer Learning (Section 3) ---\")\n",
        "\n",
        "    # [Step 3] Fine-tune ResNet-18\n",
        "    resnet = models.resnet18(pretrained=True)\n",
        "\n",
        "    # Freeze initial layers (optional, but standard for fine-tuning)\n",
        "    for param in resnet.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Replace final layer\n",
        "    num_ftrs = resnet.fc.in_features\n",
        "    resnet.fc = nn.Linear(num_ftrs, num_classes)\n",
        "    resnet = resnet.to(device)\n",
        "\n",
        "    optimizer = optim.Adam(resnet.fc.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    best_resnet_acc = 0.0\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        _, train_acc = train_one_epoch(resnet, train_loader, criterion, optimizer)\n",
        "        _, val_acc = evaluate(resnet, val_loader, criterion)\n",
        "        print(f\"ResNet Epoch {epoch+1}: Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "        if val_acc > best_resnet_acc:\n",
        "            best_resnet_acc = val_acc\n",
        "            torch.save(resnet.state_dict(), 'best_resnet.pth')\n",
        "\n",
        "    return best_resnet_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDGrDpRrGL5w",
        "outputId": "f58ece54-b2e3-4888-811c-7e718ac8c940"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "########################################\n",
            "PROCESSING DATASET: CATS_DOGS\n",
            "########################################\n",
            "Preparing data for: CATS_DOGS...\n",
            "Download complete.\n",
            "Extracting dataset...\n",
            "Extraction complete.\n",
            "Cleanup complete. Removed 1738 corrupt images.\n",
            "\n",
            "Training: Act=relu, Init=xavier, Opt=sgd\n",
            "  -> New Best Accuracy: 0.5824\n",
            "Training: Act=relu, Init=xavier, Opt=adam\n",
            "  -> New Best Accuracy: 0.7105\n",
            "Training: Act=relu, Init=xavier, Opt=rmsprop\n",
            "Training: Act=relu, Init=kaiming, Opt=sgd\n",
            "Training: Act=relu, Init=kaiming, Opt=adam\n",
            "  -> New Best Accuracy: 0.7412\n",
            "Training: Act=relu, Init=kaiming, Opt=rmsprop\n",
            "Training: Act=relu, Init=random, Opt=sgd\n",
            "Training: Act=relu, Init=random, Opt=adam\n",
            "Training: Act=relu, Init=random, Opt=rmsprop\n",
            "Training: Act=tanh, Init=xavier, Opt=sgd\n",
            "Training: Act=tanh, Init=xavier, Opt=adam\n",
            "Training: Act=tanh, Init=xavier, Opt=rmsprop\n",
            "Training: Act=tanh, Init=kaiming, Opt=sgd\n",
            "Training: Act=tanh, Init=kaiming, Opt=adam\n",
            "Training: Act=tanh, Init=kaiming, Opt=rmsprop\n",
            "Training: Act=tanh, Init=random, Opt=sgd\n",
            "Training: Act=tanh, Init=random, Opt=adam\n",
            "Training: Act=tanh, Init=random, Opt=rmsprop\n",
            "Training: Act=leaky_relu, Init=xavier, Opt=sgd\n",
            "Training: Act=leaky_relu, Init=xavier, Opt=adam\n",
            "  -> New Best Accuracy: 0.7550\n",
            "Training: Act=leaky_relu, Init=xavier, Opt=rmsprop\n",
            "Training: Act=leaky_relu, Init=kaiming, Opt=sgd\n",
            "Training: Act=leaky_relu, Init=kaiming, Opt=adam\n",
            "  -> New Best Accuracy: 0.7820\n",
            "Training: Act=leaky_relu, Init=kaiming, Opt=rmsprop\n",
            "Training: Act=leaky_relu, Init=random, Opt=sgd\n",
            "Training: Act=leaky_relu, Init=random, Opt=adam\n",
            "Training: Act=leaky_relu, Init=random, Opt=rmsprop\n",
            "\n",
            "Best Config Saved: leaky_relu_kaiming_adam with Acc: 0.7820\n",
            "\n",
            "ResNet Epoch 1: Val Acc: 0.9150\n",
            "ResNet Epoch 2: Val Acc: 0.9480\n",
            "\n",
            "########################################\n",
            "PROCESSING DATASET: CIFAR10\n",
            "########################################\n",
            "Preparing data for: CIFAR10...\n",
            "\n",
            "Training: Act=relu, Init=xavier, Opt=sgd\n",
            "  -> New Best Accuracy: 0.3105\n",
            "Training: Act=relu, Init=xavier, Opt=adam\n",
            "  -> New Best Accuracy: 0.4820\n",
            "Training: Act=relu, Init=xavier, Opt=rmsprop\n",
            "Training: Act=relu, Init=kaiming, Opt=sgd\n",
            "Training: Act=relu, Init=kaiming, Opt=adam\n",
            "  -> New Best Accuracy: 0.5215\n",
            "Training: Act=relu, Init=kaiming, Opt=rmsprop\n",
            "Training: Act=relu, Init=random, Opt=sgd\n",
            "Training: Act=relu, Init=random, Opt=adam\n",
            "Training: Act=relu, Init=random, Opt=rmsprop\n",
            "Training: Act=tanh, Init=xavier, Opt=sgd\n",
            "Training: Act=tanh, Init=xavier, Opt=adam\n",
            "Training: Act=tanh, Init=xavier, Opt=rmsprop\n",
            "Training: Act=tanh, Init=kaiming, Opt=sgd\n",
            "Training: Act=tanh, Init=kaiming, Opt=adam\n",
            "Training: Act=tanh, Init=kaiming, Opt=rmsprop\n",
            "Training: Act=tanh, Init=random, Opt=sgd\n",
            "Training: Act=tanh, Init=random, Opt=adam\n",
            "Training: Act=tanh, Init=random, Opt=rmsprop\n",
            "Training: Act=leaky_relu, Init=xavier, Opt=sgd\n",
            "Training: Act=leaky_relu, Init=xavier, Opt=adam\n",
            "  -> New Best Accuracy: 0.5410\n",
            "Training: Act=leaky_relu, Init=xavier, Opt=rmsprop\n",
            "Training: Act=leaky_relu, Init=kaiming, Opt=sgd\n",
            "Training: Act=leaky_relu, Init=kaiming, Opt=adam\n",
            "  -> New Best Accuracy: 0.5850\n",
            "Training: Act=leaky_relu, Init=kaiming, Opt=rmsprop\n",
            "Training: Act=leaky_relu, Init=random, Opt=sgd\n",
            "Training: Act=leaky_relu, Init=random, Opt=adam\n",
            "Training: Act=leaky_relu, Init=random, Opt=rmsprop\n",
            "\n",
            "Best Config Saved: leaky_relu_kaiming_adam with Acc: 0.5850\n",
            "\n",
            "ResNet Epoch 1: Val Acc: 0.7640\n",
            "ResNet Epoch 2: Val Acc: 0.8015\n",
            "\n",
            "==================================================\n",
            "FINAL DELIVERABLE SUMMARY (ALL DATASETS)\n",
            "==================================================\n",
            "\n",
            "--- CATS_DOGS Results ---\n",
            "Best Custom CNN (leaky_relu_kaiming_adam): 0.7820\n",
            "ResNet-18 Transfer Learning:      0.9480\n",
            "Conclusion: ResNet-18 outperformed the Custom CNN.\n",
            "\n",
            "--- CIFAR10 Results ---\n",
            "Best Custom CNN (leaky_relu_kaiming_adam): 0.5850\n",
            "ResNet-18 Transfer Learning:      0.8015\n",
            "Conclusion: ResNet-18 outperformed the Custom CNN.\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    # List of datasets to process\n",
        "    datasets_to_run = ['CATS_DOGS', 'CIFAR10']\n",
        "\n",
        "    final_results = {}\n",
        "\n",
        "    for dataset_name in datasets_to_run:\n",
        "        print(f\"\\n{'#'*40}\")\n",
        "        print(f\"PROCESSING DATASET: {dataset_name}\")\n",
        "        print(f\"{'#'*40}\")\n",
        "\n",
        "        # REMOVED: The manual safety check.\n",
        "        # Reason: get_dataloaders() now handles the download automatically.\n",
        "\n",
        "        try:\n",
        "            # 1. Prepare Data (This will now auto-download CATS_DOGS if missing)\n",
        "            train_loader, val_loader, num_classes = get_dataloaders(dataset_name)\n",
        "\n",
        "            # 2. Run User CNN Experiments (Section 2 of PDF)\n",
        "            best_cnn_acc, best_config = run_training_experiments(train_loader, val_loader, num_classes)\n",
        "\n",
        "            # 3. Run ResNet Experiments (Section 3 of PDF)\n",
        "            best_resnet_acc = run_resnet_transfer(train_loader, val_loader, num_classes)\n",
        "\n",
        "            # Store results for final summary\n",
        "            final_results[dataset_name] = {\n",
        "                'best_config': best_config,\n",
        "                'cnn_acc': best_cnn_acc,\n",
        "                'resnet_acc': best_resnet_acc\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"(!) Error processing {dataset_name}: {e}\")\n",
        "            continue\n",
        "\n",
        "    # 4. Final Comparison for Deliverables\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"FINAL DELIVERABLE SUMMARY (ALL DATASETS)\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    for ds, res in final_results.items():\n",
        "        print(f\"\\n--- {ds} Results ---\")\n",
        "        print(f\"Best Custom CNN ({res['best_config']}): {res['cnn_acc']:.4f}\")\n",
        "        print(f\"ResNet-18 Transfer Learning:      {res['resnet_acc']:.4f}\")\n",
        "\n",
        "        if res['resnet_acc'] > res['cnn_acc']:\n",
        "            print(\"Conclusion: ResNet-18 outperformed the Custom CNN.\")\n",
        "        else:\n",
        "            print(\"Conclusion: Custom CNN outperformed ResNet-18.\")\n",
        "    print(\"=\"*50)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyODylTzB+BTiTAAiIHRIn4a"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}